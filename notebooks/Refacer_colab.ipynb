{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghPlUjrD_xmd"
      },
      "source": [
        "# Refacer\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/xaviviro/refacer/blob/master/notebooks/Refacer_colab.ipynb)\n",
        "\n",
        "[Refacer](https://github.com/xaviviro/refacer) is an amazing tool that allows you to create deepfakes with multiple faces, giving you the option to choose which face to replace, all in one click!\n",
        "\n",
        "If you find Refacer helpful, consider giving it a star on [GitHub](https://github.com/xaviviro/refacer) Your support helps to keep the project going!\n",
        "\n",
        "Before using this Colab or the Refacer tool, please make sure to read the [Disclaimer](https://github.com/xaviviro/refacer#disclaimer) in the GitHub repository. It's very important to understand the terms of use, and the ethical implications of creating deepfakes.\n",
        "\n",
        "In this Colab, you'll be able to try out Refacer without needing to install anything on your own machine. Enjoy!\n",
        "\n",
        "*If you encounter any issues or have any suggestions, feel free to [open an issue](https://github.com/xaviviro/refacer/issues/new) on the GitHub repository.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-vlpYRr_6W7",
        "outputId": "f65d8a75-4c83-4ce4-c5cf-778d1211d1b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.10.0 which is incompatible.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\n",
            "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.3 which is incompatible.\n",
            "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.28.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.6.2.post1 which is incompatible.\n",
            "tensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.28.3 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.28.3 which is incompatible.\n",
            "torch 2.5.0+cu121 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCloning into 'refacer'...\n",
            "remote: Enumerating objects: 306, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 306 (delta 95), reused 85 (delta 85), pack-reused 195 (from 1)\u001b[K\n",
            "Receiving objects: 100% (306/306), 3.72 MiB | 37.01 MiB/s, done.\n",
            "Resolving deltas: 100% (176/176), done.\n",
            "/content/refacer/refacer\n",
            "--2024-10-28 10:14:51--  https://huggingface.co/ezioruan/inswapper_128.onnx/resolve/main/inswapper_128.onnx\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.210.77, 13.35.210.114, 13.35.210.66, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.210.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/40/3c/403ce23d3f5c02a28fcbe749205d5c8245b2812e6c948bae7abac24495779bc7/e4a3f08c753cb72d04e10aa0f7dbe3deebbf39567d4ead6dce08e98aa49e16af?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27inswapper_128.onnx%3B+filename%3D%22inswapper_128.onnx%22%3B&Expires=1730368632&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMDM2ODYzMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy80MC8zYy80MDNjZTIzZDNmNWMwMmEyOGZjYmU3NDkyMDVkNWM4MjQ1YjI4MTJlNmM5NDhiYWU3YWJhYzI0NDk1Nzc5YmM3L2U0YTNmMDhjNzUzY2I3MmQwNGUxMGFhMGY3ZGJlM2RlZWJiZjM5NTY3ZDRlYWQ2ZGNlMDhlOThhYTQ5ZTE2YWY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=buvFjpMnSs-tkSDtnve7y4YnZ53iHphwcHnViXJGK9USosW8gdmecwAgRnKwigXf%7EhtarFTQCFhBI6nBiebkXttzJHUglhXVk7PrAeLU4jaGAMq5TIOriDwhbcKkXx75z-H3TO93gO5R-R7nS3cve6TEdQsuXuI13kzXElWA5Ww8kv0CKztO-UxC3dLlbDmLrucIlJi4QmcHgdolrYBZC04cPIKTROPyU0XKvH5t4%7EuYW0fSjD5QwRL6kjvTvvA3qa2q9KlC66pLM7OsWBZ1lwSNwCjeFHZtmKj6MyghXSCVnFFNA5J9mQ64kDrPqtuAMLI29fqFWM9TmdWBHEH4KQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2024-10-28 10:14:52--  https://cdn-lfs.hf.co/repos/40/3c/403ce23d3f5c02a28fcbe749205d5c8245b2812e6c948bae7abac24495779bc7/e4a3f08c753cb72d04e10aa0f7dbe3deebbf39567d4ead6dce08e98aa49e16af?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27inswapper_128.onnx%3B+filename%3D%22inswapper_128.onnx%22%3B&Expires=1730368632&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMDM2ODYzMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy80MC8zYy80MDNjZTIzZDNmNWMwMmEyOGZjYmU3NDkyMDVkNWM4MjQ1YjI4MTJlNmM5NDhiYWU3YWJhYzI0NDk1Nzc5YmM3L2U0YTNmMDhjNzUzY2I3MmQwNGUxMGFhMGY3ZGJlM2RlZWJiZjM5NTY3ZDRlYWQ2ZGNlMDhlOThhYTQ5ZTE2YWY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=buvFjpMnSs-tkSDtnve7y4YnZ53iHphwcHnViXJGK9USosW8gdmecwAgRnKwigXf%7EhtarFTQCFhBI6nBiebkXttzJHUglhXVk7PrAeLU4jaGAMq5TIOriDwhbcKkXx75z-H3TO93gO5R-R7nS3cve6TEdQsuXuI13kzXElWA5Ww8kv0CKztO-UxC3dLlbDmLrucIlJi4QmcHgdolrYBZC04cPIKTROPyU0XKvH5t4%7EuYW0fSjD5QwRL6kjvTvvA3qa2q9KlC66pLM7OsWBZ1lwSNwCjeFHZtmKj6MyghXSCVnFFNA5J9mQ64kDrPqtuAMLI29fqFWM9TmdWBHEH4KQ__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.155.68.87, 18.155.68.37, 18.155.68.85, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.155.68.87|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 554253681 (529M) [binary/octet-stream]\n",
            "Saving to: ‘inswapper_128.onnx’\n",
            "\n",
            "inswapper_128.onnx  100%[===================>] 528.58M   215MB/s    in 2.5s    \n",
            "\n",
            "2024-10-28 10:14:54 (215 MB/s) - ‘inswapper_128.onnx’ saved [554253681/554253681]\n",
            "\n",
            "Trying FFMPEG h264_nvenc encoder\n",
            "FFMPEG h264_nvenc encoder works\n",
            "Video codec for FFMPEG: h264_nvenc\n",
            "TENSORRT mode with providers ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
            "*************** EP Error ***************\n",
            "EP Error /onnxruntime_src/onnxruntime/python/onnxruntime_pybind_state.cc:490 void onnxruntime::python::RegisterTensorRTPluginsAsCustomOps(PySessionOptions&, const onnxruntime::ProviderOptions&) Please install TensorRT libraries as mentioned in the GPU requirements page, make sure they're in the PATH or LD_LIBRARY_PATH, and that your GPU is supported.\n",
            " when using ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
            "Falling back to ['CUDAExecutionProvider', 'CPUExecutionProvider'] and retrying.\n",
            "****************************************\n",
            "*************** EP Error ***************\n",
            "EP Error /onnxruntime_src/onnxruntime/python/onnxruntime_pybind_state.cc:490 void onnxruntime::python::RegisterTensorRTPluginsAsCustomOps(PySessionOptions&, const onnxruntime::ProviderOptions&) Please install TensorRT libraries as mentioned in the GPU requirements page, make sure they're in the PATH or LD_LIBRARY_PATH, and that your GPU is supported.\n",
            " when using ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
            "Falling back to ['CUDAExecutionProvider', 'CPUExecutionProvider'] and retrying.\n",
            "****************************************\n",
            "*************** EP Error ***************\n",
            "EP Error /onnxruntime_src/onnxruntime/python/onnxruntime_pybind_state.cc:490 void onnxruntime::python::RegisterTensorRTPluginsAsCustomOps(PySessionOptions&, const onnxruntime::ProviderOptions&) Please install TensorRT libraries as mentioned in the GPU requirements page, make sure they're in the PATH or LD_LIBRARY_PATH, and that your GPU is supported.\n",
            " when using ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
            "Falling back to ['CUDAExecutionProvider', 'CPUExecutionProvider'] and retrying.\n",
            "****************************************\n",
            "inswapper-shape: [1, 3, 128, 128]\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://4dc5ca994b1d3066fb.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall numpy -y -q\n",
        "!pip install --disable-pip-version-check --root-user-action=ignore ngrok numpy==1.24.3 onnxruntime-gpu gradio insightface==0.7.3 ffmpeg_python opencv_python -q --force\n",
        "\n",
        "!git clone https://github.com/xaviviro/refacer.git\n",
        "%cd refacer\n",
        "\n",
        "!wget --content-disposition \"https://huggingface.co/ezioruan/inswapper_128.onnx/resolve/main/inswapper_128.onnx\"\n",
        "\n",
        "!python app.py --share_gradio --colab_performance\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}